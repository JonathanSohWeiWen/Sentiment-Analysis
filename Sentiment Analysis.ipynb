{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "This model was developed for Shopee Code League 2020\n",
    "The goal of this was to read in a dataset of text and give a sentiment analysis  (rating 1-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "from tensorflow import keras\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize,wordpunct_tokenize, TweetTokenizer,RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics #accuracy calculation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"datasets/sentiment analysis/train.csv\")\n",
    "test = pd.read_csv(\"datasets/sentiment analysis/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing below mainly focused on cleaning out the text data and handle unbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refined_train1\n",
      "        review_id  review\n",
      "rating                   \n",
      "1.0         12705   12705\n",
      "2.0         12705   12705\n",
      "3.0         12705   12705\n",
      "4.0         12705   12705\n",
      "5.0         12705   12705\n",
      "*********************************************\n",
      "refined_train2\n",
      "        review_id  review\n",
      "rating                   \n",
      "1.0         41865   41865\n",
      "2.0         41865   41865\n",
      "3.0         41865   41865\n",
      "4.0         41865   41865\n",
      "5.0         41865   41865\n",
      "*********************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refined_train3\n",
      "        review_id  review\n",
      "rating                   \n",
      "1.0         30000   30000\n",
      "2.0         30000   30000\n",
      "3.0         30000   30000\n",
      "4.0         30000   30000\n",
      "5.0         30000   30000\n",
      "*********************************************\n"
     ]
    }
   ],
   "source": [
    "def cleanReview(review):\n",
    "    letters = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
    "    letters = letters.lower()\n",
    "    tokens = nltk.word_tokenize(letters)\n",
    "    stops = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "    words = [w for w in tokens if not w in stops]\n",
    "#     words = [nltk.stem.SnowballStemmer('english').stem(w) for w in words]\n",
    "    words = [nltk.stem.WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "    return \" \".join(words)\n",
    "    \n",
    "train['review'] = train['review'].apply(cleanReview)\n",
    "test['review'] = test['review'].apply(cleanReview)\n",
    "ratings_count = train.groupby(['rating']).count()\n",
    "unique_train = train.drop_duplicates(subset=['review'])\n",
    "\n",
    "#By undersampling\n",
    "refined_train1 = train[train['rating']==2]\n",
    "refined_train1.dropna(inplace=True)\n",
    "for i in range(1, 6):\n",
    "    if i!=2:\n",
    "        temp_sample = train.where(train['rating']==i)\n",
    "        temp_sample.dropna(inplace=True)\n",
    "        refined_train1 = refined_train1.append(temp_sample.sample(12705, replace=False, random_state=17), ignore_index=True)\n",
    "print(\"refined_train1\")       \n",
    "print(refined_train1.groupby(['rating']).count())\n",
    "print(\"*********************************************\")\n",
    "#By oversampling\n",
    "refined_train2 = train\n",
    "refined_train2.dropna(inplace=True)\n",
    "for i in range(1, 6):\n",
    "    if i!=4:\n",
    "        temp_sample = unique_train.where(unique_train['rating']==i)\n",
    "        temp_sample.dropna(inplace=True)\n",
    "        if(i==1 or i==2):\n",
    "            temp_sample = temp_sample.append(temp_sample, ignore_index=True)\n",
    "            temp_sample = temp_sample.append(temp_sample, ignore_index=True)\n",
    "        add = 41865 - ratings_count.iloc[i-1,0]\n",
    "        refined_train2 = refined_train2.append(temp_sample.sample(add, replace=False, random_state=17), ignore_index=True)\n",
    "print(\"refined_train2\")       \n",
    "print(refined_train2.groupby(['rating']).count())\n",
    "print(\"*********************************************\")\n",
    "#By oversampling and undersampling (balanced dataset of 30000 of each)\n",
    "refined_train3 = train[train['rating']<3]\n",
    "refined_train3.dropna(inplace=True)\n",
    "for i in range(1, 6):\n",
    "    if(i==1 or i==2):\n",
    "        temp_sample = unique_train.where(unique_train['rating']==i)\n",
    "        temp_sample.dropna(inplace=True)\n",
    "        temp_sample = temp_sample.append(temp_sample, ignore_index=True)\n",
    "        add = 30000 - ratings_count.iloc[i-1,0]\n",
    "        refined_train3 = refined_train3.append(temp_sample.sample(add, replace=False, random_state=17), ignore_index=True)\n",
    "    else:\n",
    "        temp_sample = train.where(train['rating']==i)\n",
    "        temp_sample.dropna(inplace=True)\n",
    "        refined_train3 = refined_train3.append(temp_sample.sample(30000, replace=False, random_state=17), ignore_index=True)\n",
    "print(\"refined_train3\")       \n",
    "print(refined_train3.groupby(['rating']).count())\n",
    "print(\"*********************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "Tensorflow NN with tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def Model1(selected_train, stop):\n",
    "    accuracy = 0\n",
    "    #Tokenization and embeddings\n",
    "    review = selected_train.review.values\n",
    "    tokenizer = Tokenizer(num_words=9000, lower=True)\n",
    "    tokenizer.fit_on_texts(review)\n",
    "    encoded_docs = tokenizer.texts_to_sequences(review)\n",
    "    padded_sequence = pad_sequences(encoded_docs, maxlen=500)\n",
    "\n",
    "    #Model building\n",
    "    embedding_vector_length = 64\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        restore_best_weights=True)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(9000, embedding_vector_length,     \n",
    "                                         input_length=500) )\n",
    "    model.add(SpatialDropout1D(0.25))\n",
    "    model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(6, activation='relu'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy',optimizer='adam', \n",
    "                               metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    #Train the model\n",
    "    if(stop):\n",
    "        model.fit(padded_sequence, selected_train.rating.values, callbacks = [early_stopping],\n",
    "                          validation_split=0.1, epochs=3, batch_size=64)\n",
    "    else:\n",
    "        model.fit(padded_sequence, selected_train.rating.values,\n",
    "                      validation_split=0.1, epochs=3, batch_size=64)\n",
    "\n",
    "    #Use model to predict on test data\n",
    "    review = test.review.values\n",
    "    tokenizer.fit_on_texts(review)\n",
    "    encoded_docs = tokenizer.texts_to_sequences(review)\n",
    "    padded_sequence = pad_sequences(encoded_docs, maxlen=500)\n",
    "    predicted = model.predict(padded_sequence)\n",
    "\n",
    "    #getting classification results from predicted values\n",
    "    results = test\n",
    "    results['rating'] = np.nan\n",
    "    for i in range(predicted.shape[0]):\n",
    "        result = np.where(predicted[i] == np.amax(predicted[i]))\n",
    "        results.iloc[i, 2] = result[0]\n",
    "\n",
    "    #Converting results to csv\n",
    "    results = results.drop(columns=['review'])\n",
    "    results.rating = results.rating.astype(int)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "Count Vectorizer from nltk package, using MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build and train the model\n",
    "def Model2(selected_train):\n",
    "    token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "    cv = CountVectorizer(lowercase=True, stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "    text_counts= cv.fit_transform(selected_train['review'])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(text_counts, selected_train['rating'], test_size=0.1, random_state=17)\n",
    "    clf = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    print(\"MultinomialNB Accuracy:\", metrics.accuracy_score(y_test, predicted))\n",
    "\n",
    "    clf = MultinomialNB().fit(text_counts, selected_train['rating'])\n",
    "    test2 = cv.transform(test['review'])\n",
    "    test2.shape\n",
    "    predicted = clf.predict(test2)\n",
    "    results = test\n",
    "    results['rating'] = predicted\n",
    "    results = results.drop(columns=['review'])\n",
    "    results.rating = results.rating.astype(int)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "Using a TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model3(selected_train):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    text_tfidf = tfidf.fit_transform(selected_train['review'])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(text_tfidf, selected_train['rating'], test_size=0.1, random_state=17)\n",
    "    clf = MultinomialNB().fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    print(\"MultinomialNB Accuracy:\", metrics.accuracy_score(y_test, predicted)) \n",
    "\n",
    "    clf = MultinomialNB().fit(text_tfidf, selected_train['rating'])\n",
    "    test3 = tfidf.transform(test['review'])\n",
    "    predicted= clf.predict(test3)\n",
    "    results = test\n",
    "    results['rating'] = predicted\n",
    "    results = results.drop(columns=['review'])\n",
    "    results.rating = results.rating.astype(int)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4\n",
    "Combining TF-IDF and Count Vectorizer with pipeline, using hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model4(selected_train):\n",
    "    %env JOBLIB_TEMP_FOLDER=/tmp\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                              alpha=1e-3, random_state=42,\n",
    "                              max_iter=5, tol=None))\n",
    "    ])\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1,1), (1,2)],\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__alpha': (1e-2, 1e-3),\n",
    "        'clf__loss': ('hinge', 'modified_huber', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss',\n",
    "                'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'),\n",
    "        'clf__penalty': ('l1', 'l2', 'elasticnet')\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(selected_train['review'], selected_train['rating'], test_size=0.1, random_state=17)\n",
    "    text_clf.fit(X_train, y_train)\n",
    "    predicted = text_clf.predict(X_test)\n",
    "    print(\"Pipeline accuracy:\", metrics.accuracy_score(y_test, predicted))\n",
    "    \n",
    "    gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)\n",
    "    gs_clf.fit(X_train, y_train)\n",
    "    predicted = gs_clf.predict(X_test)\n",
    "    print(\"GridSearchCV accuracy:\", metrics.accuracy_score(y_test, predicted))\n",
    "    predicted = gs_clf.predict(test.review)\n",
    "    results = test\n",
    "    results['rating'] = predicted\n",
    "    results = results.drop(columns=['review'])\n",
    "    results.rating = results.rating.astype(int)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply various models to various datasets\n",
    "The result shown is for the best generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n",
      "Pipeline accuracy: 0.4623333333333333\n",
      "GridSearchCV accuracy: 0.6063333333333333\n"
     ]
    }
   ],
   "source": [
    "# results1 = Model1(refined_train1, False)\n",
    "# results2 = Model1(refined_train2, True)\n",
    "# results3 = Model1(refined_train3, False)\n",
    "# results4 = Model2(refined_train1)\n",
    "# results5 = Model2(refined_train2)\n",
    "# results6 = Model2(refined_train3)\n",
    "# results7 = Model3(refined_train1)\n",
    "# results8 = Model3(refined_train2)\n",
    "# results9 = Model3(refined_train3)\n",
    "results10 = Model4(refined_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To print results\n",
    "results10.to_csv(\"datasets/sentiment analysis/results.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
